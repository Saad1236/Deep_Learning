{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b10.jpeg', 'b4.jpeg', 'b5.jpeg', 'b6.jpeg', 'b7.jpeg', 'b8.jpeg', 'b9.jpeg', 't10.jpeg', 't2.jpeg', 't3.jpeg', 't5.jpeg', 't6.jpeg', 't8.jpeg', 't9.jpeg']\n",
      "1 name  b10.jpeg label 0\n",
      "2 name  b4.jpeg label 0\n",
      "3 name  b5.jpeg label 0\n",
      "4 name  b6.jpeg label 0\n",
      "5 name  b7.jpeg label 0\n",
      "6 name  b8.jpeg label 0\n",
      "7 name  b9.jpeg label 0\n",
      "8 name  t10.jpeg label 1\n",
      "9 name  t2.jpeg label 1\n",
      "10 name  t3.jpeg label 1\n",
      "11 name  t5.jpeg label 1\n",
      "12 name  t6.jpeg label 1\n",
      "13 name  t8.jpeg label 1\n",
      "14 name  t9.jpeg label 1\n",
      "Training Feature Vector Length: 14 Type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#train_data = \"F:/RIME/Sem3_Fall23/C1_DL/Assignment/Asg1/DS/train\"\n",
    "train_data = \"F:/RIME/Sem3_Fall23/C1_DL/Assignment/Asg1/DS/Daud/train\"  \n",
    "# List all the files in the folder\n",
    "training_images = os.listdir(train_data)\n",
    "print(training_images)\n",
    "\n",
    "# Initialize lists to store train images and labels\n",
    "train_image_features = []\n",
    "#labels = [0,0,0,1,1,1,1,1,1,1,0,0,1,1]\n",
    "labels = [0,0,0,0,0,0,0,1,1,1,1,1,1,1]\n",
    "count = 0\n",
    "\n",
    "# Create a HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "for image_file in training_images:\n",
    "    print(count+1,\"name \", image_file, 'label', labels[count])\n",
    "    # Load the image\n",
    "    if image_file is not None:\n",
    "        image = cv2.imread(image_file)\n",
    "        \n",
    "        # Resize the image to a standard size if needed\n",
    "        image = cv2.resize(image, (128, 128))  # Example size, adjust as needed\n",
    "        #cv2.imshow('img', image)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Compute HOG features\n",
    "        features = hog.compute(gray)\n",
    "        #Pixel intensity vector\n",
    "        pixel_intensity_vector_train = np.array(gray).flatten()\n",
    "        # Append the features and labels to the respective lists\n",
    "        #test_image_features.append(features.flatten())  # Flatten HOG features\n",
    "        train_image_features.append(pixel_intensity_vector_train) \n",
    "    count = count +1\n",
    "\n",
    "print('Training Feature Vector Length:', len(train_image_features), 'Type:', type(train_image_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 name  b1.jpeg\n",
      "2 name  b2.jpeg\n",
      "3 name  b3.jpeg\n",
      "4 name  t1.jpeg\n",
      "5 name  t4.jpeg\n",
      "6 name  t7.jpeg\n",
      "Test Feature Vector Length: 6 Type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Compute Feature Descriptor(HOG) of test images\n",
    "test_image_features = []\n",
    "#test_labels = [0,0,1,1,1,1]\n",
    "test_labels = [0,0,0,1,1,1]\n",
    "count = 1\n",
    "\n",
    "#image_folder = \"F:/RIME/Sem3_Fall23/C1_DL/Assignment/Asg1/DS/test\"\n",
    "image_folder = \"F:/RIME/Sem3_Fall23/C1_DL/Assignment/Asg1/DS/Daud/test\"\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Create a HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "for image_file in image_files:\n",
    "    print(count,\"name \", image_file)\n",
    "    # Load the image\n",
    "    if image_file is not None:\n",
    "        image = cv2.imread(image_file)\n",
    "        \n",
    "        # Resize the image to a standard size if needed\n",
    "        image = cv2.resize(image, (128, 128))  # Example size, adjust as needed\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Compute HOG features\n",
    "        features = hog.compute(gray)\n",
    "        #Pixel intensity vector\n",
    "        pixel_intensity_vector = np.array(gray).flatten()\n",
    "        # Append the features and labels to the respective lists\n",
    "        #test_image_features.append(features.flatten())  # Flatten HOG features\n",
    "        test_image_features.append(pixel_intensity_vector)  \n",
    "    count = count +1\n",
    "\n",
    "print('Test Feature Vector Length:', len(test_image_features), 'Type:', type(test_image_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    dist = np.sqrt(np.sum((x1 - x2)**2))\n",
    "    #print(\"euclidean_distance\", dist)\n",
    "    return dist\n",
    "\n",
    "def KNN(train_data, train_labels, test_item, k=3):\n",
    "    distances = [euclidean_distance(test_item, train_item) for train_item in train_data]\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    k_nearest_indices = sorted_indices[:k]\n",
    "    print(\"Nearest indices:\", k_nearest_indices)\n",
    "    k_nearest_labels = [train_labels[i] for i in k_nearest_indices]\n",
    "    print(\"Nearest labels: \", k_nearest_labels)\n",
    "    \n",
    "    # Perform majority voting\n",
    "    prediction = 1 if np.sum(k_nearest_labels) > k/2 else 0\n",
    "    \n",
    "    return prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Nearest indices: [3 5 4]\n",
      "Nearest labels:  [0, 0, 0]\n",
      "2\n",
      "Nearest indices: [6 0 2]\n",
      "Nearest labels:  [0, 0, 0]\n",
      "3\n",
      "Nearest indices: [5 4 3]\n",
      "Nearest labels:  [0, 0, 0]\n",
      "4\n",
      "Nearest indices: [13 11  9]\n",
      "Nearest labels:  [1, 1, 1]\n",
      "5\n",
      "Nearest indices: [11 13  7]\n",
      "Nearest labels:  [1, 1, 1]\n",
      "6\n",
      "Nearest indices: [11  7 13]\n",
      "Nearest labels:  [1, 1, 1]\n",
      "[0, 0, 0, 1, 1, 1]\n",
      "99.96 %\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded and preprocessed your data into train_data, train_labels, test_data\n",
    "k = 3\n",
    "predictions = []\n",
    "cp = 1\n",
    "for test_item in test_image_features:\n",
    "    print (cp)\n",
    "    prediction = KNN(train_image_features, labels, test_item, k)\n",
    "    predictions.append(prediction)\n",
    "    cp = cp +1 \n",
    "print(predictions)\n",
    "c=0\n",
    "Accuracy =0\n",
    "for lab in predictions:\n",
    "    if test_labels[c]==lab:\n",
    "        Accuracy = Accuracy+16.66\n",
    "    c= c+1\n",
    "print(Accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Manhattan_distance\"\n",
    "def manhattan_distance(x1, x2):\n",
    "    dist = np.sum(np.abs(x1 - x2))\n",
    "    #print(\"Manhattan_distance\", dist)\n",
    "    return dist\n",
    "\n",
    "def KNN_M(train_data, train_labels, test_item, k=3):\n",
    "    distances = [manhattan_distance(test_item, train_item) for train_item in train_data]\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    k_nearest_indices = sorted_indices[:k]\n",
    "    print(\"Nearest indices:\", k_nearest_indices)\n",
    "    k_nearest_labels = [train_labels[i] for i in k_nearest_indices]\n",
    "    print(\"Nearest labels: \", k_nearest_labels)\n",
    "    # Perform majority voting\n",
    "    prediction = 1 if np.sum(k_nearest_labels) > k/2 else 0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest indices: [10 12 11]\n",
      "Nearest labels:  [1, 1, 1]\n",
      "Nearest indices: [11 10 13]\n",
      "Nearest labels:  [1, 1, 1]\n",
      "Nearest indices: [10 12 11]\n",
      "Nearest labels:  [1, 1, 1]\n",
      "Nearest indices: [13 11  5]\n",
      "Nearest labels:  [1, 1, 0]\n",
      "Nearest indices: [13 11  5]\n",
      "Nearest labels:  [1, 1, 0]\n",
      "Nearest indices: [11 13  5]\n",
      "Nearest labels:  [1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "49.998000000000005 %\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded and preprocessed your data into train_data, train_labels, test_data\n",
    "k = 3\n",
    "predictions = []\n",
    "\n",
    "for test_item in test_image_features:\n",
    "    prediction = KNN_M(train_image_features, labels, test_item, k)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "print(predictions)\n",
    "c=0\n",
    "Accuracy =0\n",
    "for lab in predictions:\n",
    "    if test_labels[c]==lab:\n",
    "        Accuracy = Accuracy+16.666\n",
    "    c= c+1\n",
    "print(Accuracy, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
